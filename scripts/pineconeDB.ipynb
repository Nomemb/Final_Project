{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T05:16:58.088720Z",
     "start_time": "2024-12-18T05:16:55.790626Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%pip install pandas langchain langchain-core langchain-community langchain-text-splitters langchain-openai langchain-pinecone docx2txt langchain_upstage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6218586b0a150d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import dotenv \n",
    "\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10da07f7226e7b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-04T01:09:00.377569Z",
     "start_time": "2025-01-04T01:08:58.775239Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from langchain_upstage import UpstageEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "from pprint import pprint\n",
    "\n",
    "# GPT_API_KEY = os.environ.get(\"OPENAI_API_KEY\")\n",
    "UPSTAGE_API_KEY = os.environ.get(\"UPSTAGE_API_KEY\")\n",
    "PINECONE_API_KEY = os.environ.get(\"PINECONE_API_KEY\")\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1500,\n",
    "    chunk_overlap=200,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c493976160090709",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-30T10:01:56.718761Z",
     "start_time": "2024-12-30T10:01:56.704649Z"
    }
   },
   "outputs": [],
   "source": [
    "folder_path = '../data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86175e1843b29943",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-30T10:02:01.024673Z",
     "start_time": "2024-12-30T10:02:01.000327Z"
    }
   },
   "outputs": [],
   "source": [
    "document_list = []\n",
    "\n",
    "for file in os.listdir(folder_path):\n",
    "    print(file)\n",
    "    temp_loader = CSVLoader(file_path=f\"{folder_path}/{file}\", encoding='utf-8-sig')\n",
    "    temp_document_list = temp_loader.load_and_split(text_splitter=text_splitter)\n",
    "    \n",
    "    document_list.extend(temp_document_list)\n",
    "\n",
    "print(len(document_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7719061b6dab8d39",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-04T01:09:06.448010Z",
     "start_time": "2025-01-04T01:09:05.936470Z"
    }
   },
   "outputs": [],
   "source": [
    "# Upstage 에서 제공하는 Embedding Model을 활용\n",
    "embedding = UpstageEmbeddings(model=\"solar-embedding-1-large\",\n",
    "                              api_key=UPSTAGE_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5888d34b4e41a2d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-04T01:09:11.978940Z",
     "start_time": "2025-01-04T01:09:11.524428Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "index_name = 'upstage-index'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23399523e40f7306",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DB 처음 만들 때\n",
    "database = PineconeVectorStore.from_documents(document_list, embedding, index_name=index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e740ffcf8368014",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-04T01:09:15.404288Z",
     "start_time": "2025-01-04T01:09:13.088429Z"
    }
   },
   "outputs": [],
   "source": [
    "# 만들어 놓은 DB가 있을 때\n",
    "database = PineconeVectorStore.from_existing_index(index_name=index_name, embedding=embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e7d72561431bf2",
   "metadata": {},
   "source": [
    "# Vectorstore 유사도 검색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86e50ac276f7496",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-04T01:41:19.846034Z",
     "start_time": "2025-01-04T01:41:17.991659Z"
    }
   },
   "outputs": [],
   "source": [
    "query = ('회수가 불필요한 상품')\n",
    "\n",
    "results = database.similarity_search_with_score(query=query, k=3)\n",
    "for doc, score in results:\n",
    "    print(f\"* [SIM={score:3f}] {doc.page_content} [{doc.metadata}]\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e6e31fe66017cf",
   "metadata": {},
   "source": [
    "# LLM 질의 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704519ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install langchain_google_genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f3da4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ChatGoogleGenerativeAI 언어 모델을 초기화합니다.\n",
    "model = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-flash-latest\",  # 사용할 모델을 지정합니다.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35eeee402a11d206",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-04T01:50:56.945106Z",
     "start_time": "2025-01-04T01:50:51.756239Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "retriever = database.as_retriever(\n",
    "    search_type=\"mmr\", search_kwargs={\"k\": 3, \"fetch_k\": 5}\n",
    ")\n",
    "\n",
    "template = \"\"\"\n",
    "[context]: {context}\n",
    "---\n",
    "[질의]: {query}\n",
    "\n",
    "위의 [context] 정보 내에서 [질의]에 대해 상담사 입장에서 사용자가 만족할 수 있을 정도로 성의있게 답하세요.\n",
    "단, [context] 정보에 없는 내용을 답해서는 안됩니다. 최대한 문장을 쉼표로 끊어서 대답하기 보다는, 온점으로 문장을 끊어주세요.\n",
    "이 모든 정보를 종합해서 2~3줄의 구어체로 답해주세요.\n",
    "\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\", temperature=0)\n",
    "\n",
    "def merge_pages(pages):\n",
    "    merged = \"\\n\\n\".join(page.page_content for page in pages)\n",
    "    return merged\n",
    "\n",
    "chain = (\n",
    "    {\"query\": RunnablePassthrough(), \"context\": retriever | merge_pages}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "answer = chain.invoke(\"상품의 상태를 확인\").replace('  ', ' ').split('.')\n",
    "print(\"Answer : \", end='')\n",
    "for ans in answer:\n",
    "    print(ans + '.')\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
