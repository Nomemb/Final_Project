{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T05:16:58.088720Z",
     "start_time": "2024-12-18T05:16:55.790626Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%pip install pandas langchain langchain-core langchain-community langchain-text-splitters langchain-openai langchain-pinecone docx2txt langchain_upstage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6218586b0a150d",
   "metadata": {},
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from langchain_upstage import UpstageEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "from dotenv import load_dotenv\n",
    "from pprint import pprint\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "GPT_API_KEY = os.environ[\"GPT_API_KEY\"]\n",
    "PINECONE_API_KEY = os.environ[\"PINECONE_API_KEY\"]\n",
    "UPSTAGE_API_KEY = os.environ[\"UPSTAGE_API_KEY\"]\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1500,\n",
    "    chunk_overlap=200,\n",
    ")"
   ],
   "id": "b9f0fbfbfdd1f0ad"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "folder_path = '../data'",
   "id": "6c19289eb785cad9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "document_list = []\n",
    "\n",
    "for file in os.listdir(folder_path):\n",
    "    print(file)\n",
    "    temp_loader = CSVLoader(file_path=f\"{folder_path}/{file}\", encoding='utf-8-sig')\n",
    "    temp_document_list = temp_loader.load_and_split(text_splitter=text_splitter)\n",
    "    \n",
    "    document_list.extend(temp_document_list)\n",
    "\n",
    "print(len(document_list))"
   ],
   "id": "6f380ad09762a365"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Upstage 에서 제공하는 Embedding Model을 활용\n",
    "embedding = UpstageEmbeddings(model=\"solar-embedding-1-large\",\n",
    "                              api_key=UPSTAGE_API_KEY)"
   ],
   "id": "be17f5a512b2346f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "index_name = 'upstage-index'"
   ],
   "id": "c5d07f02320146c3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23399523e40f7306",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DB 처음 만들 때\n",
    "database = PineconeVectorStore.from_documents(document_list, embedding, index_name=index_name)\n"
   ],
   "id": "5dfc1d543ad32080"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 만들어 놓은 DB가 있을 때\n",
    "database = PineconeVectorStore.from_existing_index(index_name=index_name, embedding=embedding)"
   ],
   "id": "9d9c8e1799dea064"
  },
  {
   "cell_type": "markdown",
   "source": "# Vectorstore 유사도 검색",
   "id": "f9b901d1c08e69c0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "query = '결제 후 주문 취소가 가능한가요?'\n",
    "\n",
    "results = database.similarity_search_with_score(query=query, k=3)\n",
    "for doc, score in results:\n",
    "    print(f\"* [SIM={score:3f}] {doc.page_content} [{doc.metadata}]\")\n",
    "    "
   ],
   "id": "130715d5f45c8266"
  },
  {
   "cell_type": "markdown",
   "source": "# LLM 질의 테스트",
   "id": "b4b635c5c5602fb0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "retriever = database.as_retriever(\n",
    "    search_type=\"mmr\", search_kwargs={\"k\": 3, \"fetch_k\": 5}\n",
    ")\n",
    "\n",
    "template = \"\"\"\n",
    "[context]: {context}\n",
    "---\n",
    "[질의]: {query}\n",
    "\n",
    "7년 이상의 경력을 가진 상담사라고 생각하고, 위의 [context] 정보 내에서 [질의]에 대해 상담사 입장에서 사용자가 만족할 수 있을 정도로 성의있게 답해주세요.\n",
    "최대한 문장을 쉼표로 끊어서 대답하기 보다는 온점으로 문장을 끊어주세요. \n",
    "문장의 마무리는 '~요' 보다는 '~다'로 끝나는 쪽이 전문적으로 보입니다.\n",
    "\n",
    "또한, 상담사는 가능한 선에서 직접 확인+안내+해결을 도와주는 직원이므로 직접 확인 후 해결까지 돕는 방향으로 작성해 주세요.\n",
    "그리고, 사용자의 편의를 위해 서비스 특성 상 쿠션어를 사용하시면 좋습니다.\n",
    "쿠션어의 예시는 다음과 같습니다.\n",
    "예시)\n",
    "불편을 드려 죄송합니다.\n",
    "번거로우시겠지만~\n",
    "~하는 점 양해 부탁드립니다.\n",
    "~할 예정입니다.\n",
    "~를 부탁드립니다.\n",
    "\n",
    "위 사항들을 종합해서 2~3줄로 상담사가 활용하기 좋게 대본을 만들어 주세요.\n",
    "\n",
    "만약, 조건별로 안내 내용이 다른 경우\n",
    "1차 응대 (양해멘트 or 1차 안내 등) + 정보 확인 멘트로 대본을 구성하면 됩니다.\n",
    "정보 확인 멘트는 \"정확한 상담을 위해 주문하신 주문 번호 확인 부탁드립니다.\" 입니다.\n",
    "문서의 아래에 각 조건별 대응 방법을 기술해 주세요.\n",
    "\n",
    "단, 제일 중요한 것은 [context] 정보에 없는 내용을 답해서는 안됩니다. [context]에 정보가 없거나 문서들의 유사성이 0.2 이하로 떨어질 경우, \"문의주신 내용은 확인이 필요하여 지금 답변드리기 어려울 것 같습니다. 번거로우시겠지만 확인 후에 다시 연락드려도 괜찮을까요?\" 라고 답해주세요.\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\", temperature=0)\n",
    "\n",
    "def merge_pages(pages):\n",
    "    merged = \"\".join(page.page_content for page in pages)\n",
    "    return merged\n",
    "\n",
    "chain = (\n",
    "    {\"query\": RunnablePassthrough(), \"context\": retriever | merge_pages}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "    "
   ],
   "id": "7149543ec13c8e5f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 유사도 보기\n",
    "# results = database.similarity_search_with_score(query=query, k=3)\n",
    "# pprint(results)\n",
    "query = '결제 시 카드 정보는 어떻게 보호되나요?'\n",
    "results = database.similarity_search_with_score(query=query, k=3)\n",
    "pprint(results)\n",
    "\n",
    "print()\n",
    "answer = chain.invoke(query).replace('  ', ' ').split('.')\n",
    "print(\"Answer : \", end='')\n",
    "for ans in answer:  \n",
    "    print(ans + '.')"
   ],
   "id": "735da33e50d3439f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# OLLAMA TEST",
   "id": "363722a47ac16cc9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "retriever = database.as_retriever(\n",
    "    search_type=\"mmr\", search_kwargs={\"k\": 3, \"fetch_k\": 5}\n",
    ")\n",
    "\n",
    "template = \"\"\"\n",
    "[context]: {context}\n",
    "---\n",
    "[질의]: {query}\n",
    "\n",
    "7년 이상의 경력을 가진 상담사라고 생각하고, 위의 [context] 정보 내에서 [질의]에 대해 상담사 입장에서 사용자가 만족할 수 있을 정도로 성의있게 답해주세요.\n",
    "최대한 문장을 쉼표로 끊어서 대답하기 보다는 온점으로 문장을 끊어주세요. \n",
    "문장의 마무리는 '~요' 보다는 '~다'로 끝나는 쪽이 전문적으로 보입니다.\n",
    "또한, 상담사는 가능한 선에서 직접 확인+안내+해결을 도와주는 직원이므로 직접 확인 후 해결까지 돕는 방향으로 작성해 주세요.\n",
    "그리고, 사용자의 편의를 위해 서비스 특성 상 쿠션어를 사용하시면 좋습니다.\n",
    "\n",
    "쿠션어의 예시는 다음과 같습니다.\n",
    "예시)\n",
    "불편을 드려 죄송합니다.\n",
    "번거로우시겠지만~\n",
    "~하는 점 양해 부탁드립니다.\n",
    "~할 예정입니다.\n",
    "~를 부탁드립니다.\n",
    "\n",
    "위 사항들을 종합해서 2~3줄로 상담사가 활용하기 좋게 대본을 만들어 주세요.\n",
    "\n",
    "단, 제일 중요한 것은 [context] 정보에 없는 내용을 답해서는 안됩니다. [context]에 정보가 없거나 문서들의 유사성이 0.2 이하로 떨어질 경우, \"문의주신 내용은 확인이 필요하여 지금 답변드리기 어려울 것 같습니다. 번거로우시겠지만 확인 후에 다시 연락드려도 괜찮을까요?\" 라고 답해주세요.\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "llm = ChatOllama(\n",
    "    model=\"llama3.1:8b\"\n",
    ")\n",
    "\n",
    "def merge_pages(pages):\n",
    "    merged = \"\".join(page.page_content for page in pages)\n",
    "    return merged\n",
    "\n",
    "chain = (\n",
    "    {\"query\": RunnablePassthrough(), \"context\": retriever | merge_pages}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "# 유사도 보기\n",
    "# results = database.similarity_search_with_score(query=query, k=3)\n",
    "# pprint(results)\n",
    "query = '결제 후 주문 취소가 가능한가요?'\n",
    "results = database.similarity_search_with_score(query=query, k=3)\n",
    "pprint(results)\n",
    "\n",
    "print()\n",
    "answer = chain.invoke(query).replace('  ', ' ').split('.')\n",
    "print(\"Answer : \", end='')\n",
    "for ans in answer:  \n",
    "    print(ans + '.')\n",
    "    "
   ],
   "id": "cb7be6f438b8b0c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "a85500367870cbbe"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
